{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "RESULT_DIR = '/media/ponbac/BigHDD/ethereum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_addresses = pd.read_csv(f'{RESULT_DIR}/known-addresses.csv')\n",
    "\n",
    "flagged: pd.DataFrame = known_addresses[known_addresses.legitimacy == 0]\n",
    "print(f'found {len(flagged)} addresses flagged as illegitimate.')\n",
    "pre_flagged = len(flagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POISON_DIR = f'{RESULT_DIR}/blacklist/poison'\n",
    "\n",
    "FLAGGED_RESULT = f'{POISON_DIR}/poison-flagged-result.csv'\n",
    "FLAGGED_RUNDATA = f'{POISON_DIR}/poison-flagged-rundata.csv'\n",
    "poison_flagged_rundata = pd.read_csv(FLAGGED_RUNDATA, dtype={'chunk': int})\n",
    "poison_flagged_rundata['algorithm'] = 'Poison (Flagged)'\n",
    "\n",
    "TORNADO_RESULT = f'{POISON_DIR}/poison-tornado-result.csv'\n",
    "TORNADO_RUNDATA = f'{POISON_DIR}/poison-tornado-rundata.csv'\n",
    "poison_tornado_rundata = pd.read_csv(TORNADO_RUNDATA, dtype={'chunk': int})\n",
    "poison_tornado_rundata['algorithm'] = 'Poison (Tornado)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAIRCUT_DIR = f'{RESULT_DIR}/blacklist/haircut'\n",
    "\n",
    "FLAGGED_RESULT = f'{HAIRCUT_DIR}/haircut-flagged-result.csv'\n",
    "FLAGGED_RUNDATA = f'{HAIRCUT_DIR}/haircut-flagged-rundata.csv'\n",
    "haircut_flagged_rundata = pd.read_csv(FLAGGED_RUNDATA)\n",
    "haircut_flagged_rundata['algorithm'] = 'Haircut (Flagged)'\n",
    "\n",
    "TORNADO_RESULT = f'{HAIRCUT_DIR}/haircut-tornado-result.csv'\n",
    "TORNADO_RUNDATA = f'{HAIRCUT_DIR}/haircut-tornado-rundata.csv'\n",
    "haircut_tornado_rundata = pd.read_csv(TORNADO_RUNDATA)\n",
    "haircut_tornado_rundata['algorithm'] = 'Haircut (Tornado)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "with open(FLAGGED_RESULT ,'r') as read_obj:\n",
    "    csv_reader = reader(read_obj)\n",
    "    \n",
    "    threshold_0 = 0\n",
    "    threshold_0001 = 0.001\n",
    "    threshold_001 = 0.01\n",
    "    threshold_01 = 0.1\n",
    "    threshold_05 = 0.5\n",
    "    threshold_1 = 1\n",
    "    threshold_2 = 2\n",
    "    threshold_5 = 5\n",
    "    threshold_10 = 10\n",
    "    threshold_50 = 50\n",
    "    threshold_100 = 100\n",
    "    threshold_500 = 500\n",
    "    threshold_1000 = 1000\n",
    "    threshold_5000 = 5000\n",
    "    threshold_10000 = 10000\n",
    "    threshold_50000 = 50000\n",
    "    threshold_100000 = 100000\n",
    "\n",
    "    total = 0\n",
    "    count_0 = 0\n",
    "    count_0001 = 0\n",
    "    count_001 = 0\n",
    "    count_01 = 0\n",
    "    count_05 = 0\n",
    "    count_1 = 0\n",
    "    count_2 = 0\n",
    "    count_5 = 0\n",
    "    count_10 = 0\n",
    "    count_50 = 0\n",
    "    count_100 = 0\n",
    "    count_500 = 0\n",
    "    count_1000 = 0\n",
    "    count_5000 = 0\n",
    "    count_10000 = 0\n",
    "    count_50000 = 0\n",
    "    count_100000 = 0\n",
    "    for i, row in enumerate(csv_reader):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        balance = float(row[1])\n",
    "        #taint = balance * float(row[2]) / 1e18\n",
    "        taint = float(row[1]) / 1e18\n",
    "        \n",
    "        if taint >= threshold_0:\n",
    "            count_0 += 1\n",
    "        if taint >= threshold_0001:\n",
    "            count_0001 += 1\n",
    "        if taint >= threshold_001:\n",
    "            count_001 += 1\n",
    "        if taint >= threshold_01:\n",
    "            count_01 += 1\n",
    "        if taint >= threshold_05:\n",
    "            count_05 += 1\n",
    "        if taint >= threshold_1:\n",
    "            count_1 += 1\n",
    "        if taint >= threshold_2:\n",
    "            count_2 += 1\n",
    "        if taint >= threshold_5:\n",
    "            count_5 += 1\n",
    "        if taint >= threshold_10:\n",
    "            count_10 += 1\n",
    "        if taint >= threshold_50:\n",
    "            count_50 += 1\n",
    "        if taint >= threshold_100:\n",
    "            count_100 += 1\n",
    "        if taint >= threshold_500:\n",
    "            count_500 += 1\n",
    "        if taint >= threshold_1000:\n",
    "            count_1000 += 1\n",
    "        if taint >= threshold_5000:\n",
    "            count_5000 += 1\n",
    "        if taint >= threshold_10000:\n",
    "            count_10000 += 1\n",
    "        if taint >= threshold_50000:\n",
    "            count_50000 += 1\n",
    "        if taint >= threshold_100000:\n",
    "            count_100000 += 1\n",
    "        total += 1\n",
    "\n",
    "    count_0 -= pre_flagged\n",
    "    count_0001 -= pre_flagged\n",
    "    count_001 -= pre_flagged\n",
    "    count_01 -= pre_flagged\n",
    "    count_05 -= pre_flagged\n",
    "    count_1 -= pre_flagged\n",
    "    count_2 -= pre_flagged\n",
    "    count_5 -= pre_flagged\n",
    "    count_10 -= pre_flagged\n",
    "    count_50 -= pre_flagged\n",
    "    count_100 -= pre_flagged\n",
    "    count_500 -= pre_flagged\n",
    "    count_1000 -= pre_flagged\n",
    "    count_5000 -= pre_flagged\n",
    "    count_10000 -= pre_flagged\n",
    "    count_50000 -= pre_flagged\n",
    "    count_100000 -= pre_flagged\n",
    "\n",
    "    print(\n",
    "        f'Found {count_0:,} accounts with more than {threshold_0} tainted ETH')\n",
    "    print(\n",
    "        f'Found {count_0001:,} accounts with more than {threshold_0001} tainted ETH')\n",
    "    print(\n",
    "        f'Found {count_001:,} accounts with more than {threshold_001} tainted ETH')\n",
    "    print(\n",
    "        f'Found {count_01:,} accounts with more than {threshold_01} tainted ETH')\n",
    "    print(\n",
    "        f'Found {count_05:,} accounts with more than {threshold_05} tainted ETH')\n",
    "    print(\n",
    "        f'Found {count_1:,} accounts with more than {threshold_1} tainted ETH')\n",
    "    print(\n",
    "        f'Found {count_2:,} accounts with more than {threshold_2} tainted ETH')\n",
    "    print(\n",
    "        f'Found {count_5:,} accounts with more than {threshold_5} tainted ETH')\n",
    "    print(\n",
    "        f'Found {count_10:,} accounts with more than {threshold_10} tainted ETH')\n",
    "    print(\n",
    "        f'Found {count_50:,} accounts with more than {threshold_50} tainted ETH')\n",
    "    print(\n",
    "        f'Found {count_100:,} accounts with more than {threshold_100} tainted ETH')\n",
    "    print(\n",
    "        f'Found {count_500:,} accounts with more than {threshold_500} tainted ETH')\n",
    "    print(\n",
    "        f'Found {count_1000:,} accounts with more than {threshold_1000:,} tainted ETH')\n",
    "    print(\n",
    "        f'Found {count_5000:,} accounts with more than {threshold_5000:,} tainted ETH')\n",
    "    print(\n",
    "        f'Found {count_10000:,} accounts with more than {threshold_10000:,} tainted ETH')\n",
    "    print(\n",
    "        f'Found {count_50000:,} accounts with more than {threshold_50000:,} tainted ETH')\n",
    "    print(\n",
    "        f'Found {count_100000:,} accounts with more than {threshold_100000:,} tainted ETH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENIORITY_DIR = f'{RESULT_DIR}/blacklist/seniority'\n",
    "\n",
    "FLAGGED_RESULT = f'{SENIORITY_DIR}/seniority-flagged-result.csv'\n",
    "FLAGGED_RUNDATA = f'{SENIORITY_DIR}/seniority-flagged-rundata.csv'\n",
    "seniority_flagged_rundata = pd.read_csv(FLAGGED_RUNDATA)\n",
    "seniority_flagged_rundata['algorithm'] = 'Seniority (Flagged)'\n",
    "\n",
    "TORNADO_RESULT = f'{SENIORITY_DIR}/seniority-tornado-result.csv'\n",
    "TORNADO_RUNDATA = f'{SENIORITY_DIR}/seniority-tornado-rundata.csv'\n",
    "seniority_tornado_rundata = pd.read_csv(TORNADO_RUNDATA)\n",
    "seniority_tornado_rundata['algorithm'] = 'Seniority (Tornado)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "with open(FLAGGED_RESULT, 'r') as read_obj:\n",
    "    csv_reader = reader(read_obj)\n",
    "\n",
    "    threshold_0 = 0\n",
    "    threshold_01 = 0.1\n",
    "    threshold_05 = 0.5\n",
    "    threshold_1 = 1\n",
    "    threshold_2 = 2\n",
    "    threshold_5 = 5\n",
    "    threshold_10 = 10\n",
    "    threshold_50 = 50\n",
    "    threshold_100 = 100\n",
    "    threshold_500 = 500\n",
    "    threshold_1000 = 1000\n",
    "    threshold_5000 = 5000\n",
    "    threshold_10000 = 10000\n",
    "    threshold_50000 = 50000\n",
    "    threshold_100000 = 100000\n",
    "\n",
    "    total = 0\n",
    "    count_0 = 0\n",
    "    count_01 = 0\n",
    "    count_05 = 0\n",
    "    count_1 = 0\n",
    "    count_2 = 0\n",
    "    count_5 = 0\n",
    "    count_10 = 0\n",
    "    count_50 = 0\n",
    "    count_100 = 0\n",
    "    count_500 = 0\n",
    "    count_1000 = 0\n",
    "    count_5000 = 0\n",
    "    count_10000 = 0\n",
    "    count_50000 = 0\n",
    "    count_100000 = 0\n",
    "    for i, row in enumerate(csv_reader):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        row[1] = float(row[1]) / 10**18\n",
    "        if row[1] > threshold_0:\n",
    "            count_0 += 1\n",
    "        if row[1] > threshold_01:\n",
    "            count_01 += 1\n",
    "        if row[1] > threshold_05:\n",
    "            count_05 += 1\n",
    "        if row[1] > threshold_1:\n",
    "            count_1 += 1\n",
    "        if row[1] > threshold_2:\n",
    "            count_2 += 1\n",
    "        if row[1] > threshold_5:\n",
    "            count_5 += 1\n",
    "        if row[1] > threshold_10:\n",
    "            count_10 += 1\n",
    "        if row[1] > threshold_50:\n",
    "            count_50 += 1\n",
    "        if row[1] > threshold_100:\n",
    "            count_100 += 1\n",
    "        if row[1] > threshold_500:\n",
    "            count_500 += 1\n",
    "        if row[1] > threshold_1000:\n",
    "            count_1000 += 1\n",
    "        if row[1] > threshold_5000:\n",
    "            count_5000 += 1\n",
    "        if row[1] > threshold_10000:\n",
    "            count_10000 += 1\n",
    "        if row[1] > threshold_50000:\n",
    "            count_50000 += 1\n",
    "        if row[1] > threshold_100000:\n",
    "            count_100000 += 1\n",
    "        total += 1\n",
    "\n",
    "    count_0 -= pre_flagged\n",
    "    count_01 -= pre_flagged\n",
    "    count_05 -= pre_flagged\n",
    "    count_1 -= pre_flagged\n",
    "    count_2 -= pre_flagged\n",
    "    count_5 -= pre_flagged\n",
    "    count_10 -= pre_flagged\n",
    "    count_50 -= pre_flagged\n",
    "    count_100 -= pre_flagged\n",
    "    count_500 -= pre_flagged\n",
    "    count_1000 -= pre_flagged\n",
    "    count_5000 -= pre_flagged\n",
    "    count_10000 -= pre_flagged\n",
    "    count_50000 -= pre_flagged\n",
    "    count_100000 -= pre_flagged\n",
    "\n",
    "    print(\n",
    "        f'Found {count_0:,} accounts with more than {threshold_0} ETH')\n",
    "    print(\n",
    "        f'Found {count_01:,} accounts with more than {threshold_01} ETH')\n",
    "    print(\n",
    "        f'Found {count_05:,} accounts with more than {threshold_05} ETH')\n",
    "    print(\n",
    "        f'Found {count_1:,} accounts with more than {threshold_1} ETH')\n",
    "    print(\n",
    "        f'Found {count_2:,} accounts with more than {threshold_2} ETH')\n",
    "    print(\n",
    "        f'Found {count_5:,} accounts with more than {threshold_5} ETH')\n",
    "    print(\n",
    "        f'Found {count_10:,} accounts with more than {threshold_10} ETH')\n",
    "    print(\n",
    "        f'Found {count_50:,} accounts with more than {threshold_50} ETH')\n",
    "    print(\n",
    "        f'Found {count_100:,} accounts with more than {threshold_100} ETH')\n",
    "    print(\n",
    "        f'Found {count_500:,} accounts with more than {threshold_500} ETH')\n",
    "    print(\n",
    "        f'Found {count_1000:,} accounts with more than {threshold_1000:,} ETH')\n",
    "    print(\n",
    "        f'Found {count_5000:,} accounts with more than {threshold_5000:,} ETH')\n",
    "    print(\n",
    "        f'Found {count_10000:,} accounts with more than {threshold_10000:,} ETH')\n",
    "    print(\n",
    "        f'Found {count_50000:,} accounts with more than {threshold_50000:,} ETH')\n",
    "    print(\n",
    "        f'Found {count_100000:,} accounts with more than {threshold_100000:,} ETH')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Set the style and color palette\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "# Create a list of thresholds\n",
    "thresholds = [0, 0.1, 0.5, 1, 2, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000]\n",
    "\n",
    "# Create a list of counts for each threshold\n",
    "counts = [count_0, count_01, count_05, count_1, count_2, count_5, count_10, count_50, count_100, count_500, count_1000, count_5000, count_10000, count_50000, count_100000]\n",
    "\n",
    "data = pd.DataFrame({'thresholds': thresholds, 'counts': counts})\n",
    "\n",
    "# Plot the data with log scaling\n",
    "plt = sns.lineplot(x=\"thresholds\", y=\"counts\", data=data)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "# Combine rundata\n",
    "rundata = pd.concat([poison_flagged_rundata, poison_tornado_rundata])\n",
    "rundata = pd.concat([rundata, haircut_flagged_rundata])\n",
    "rundata = pd.concat([rundata, haircut_tornado_rundata])\n",
    "rundata = pd.concat([rundata, seniority_flagged_rundata])\n",
    "rundata = pd.concat([rundata, seniority_tornado_rundata])\n",
    "rundata = rundata.reset_index(drop=True)\n",
    "\n",
    "# Create a visualization\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(rc={'figure.figsize': (14.7, 8.27)})\n",
    "sns.lineplot(x='max_block', y='n_blacklisted', hue='algorithm',\n",
    "             data=rundata).set(title='Addresses blacklisted over time', xlabel='Block number', ylabel='# of addresses blacklisted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='max_block', y='ram_usage_gb', hue='algorithm',\n",
    "             data=rundata).set(title='RAM usage over time', xlabel='Block number', ylabel='RAM used (GB)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rundata.processed_after = rundata.processed_after.apply(lambda x: (int(x.split(' ')[2].split(':')[0]) * 60 + int(x.split(' ')[2].split(':')[1])) / 60)\n",
    "sns.lineplot(x='max_block', y='processed_after', hue='algorithm', data=rundata).set(title='Time to reach block', xlabel='Block number', ylabel='Processed after (hours)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haircut stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "RESULT_DIR = '/media/ponbac/BigHDD/ethereum'\n",
    "HAIRCUT_DIR = f'{RESULT_DIR}/blacklist/haircut'\n",
    "FLAGGED_RESULT = f'{HAIRCUT_DIR}/haircut-flagged-result.csv'\n",
    "TORNADO_RESULT = f'{HAIRCUT_DIR}/haircut-tornado-result.csv'\n",
    "\n",
    "CHUNK_SIZE = 100000\n",
    "#flagged_iter = pd.read_csv(FLAGGED_RESULT, chunksize=CHUNK_SIZE)\n",
    "#tornado_iter = pd.read_csv(TORNADO_RESULT, chunksize=CHUNK_SIZE)\n",
    "\n",
    "def calc_addresses_over_threshold(iter, threshold: float, chunk_size=100000, n_iter=984, isWei=False):\n",
    "    THRESHOLD_ETH = threshold\n",
    "    addresses_over_threshold = 0\n",
    "    pbar = tqdm(total=n_iter)\n",
    "    for chunk in iter:\n",
    "        if isWei:\n",
    "            chunk = chunk[chunk['taint'] / 10**18 > THRESHOLD_ETH]\n",
    "        else:\n",
    "            chunk = chunk[chunk['taint'] > THRESHOLD_ETH]\n",
    "        addresses_over_threshold += len(chunk)\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    print(f'Addresses over {THRESHOLD_ETH} ETH: {addresses_over_threshold}')\n",
    "\n",
    "print('Flagged')\n",
    "calc_addresses_over_threshold(pd.read_csv(FLAGGED_RESULT, chunksize=CHUNK_SIZE), 0.001, n_iter=1516)\n",
    "calc_addresses_over_threshold(pd.read_csv(FLAGGED_RESULT, chunksize=CHUNK_SIZE), 0.01, n_iter=1516)\n",
    "calc_addresses_over_threshold(pd.read_csv(FLAGGED_RESULT, chunksize=CHUNK_SIZE), 0.1, n_iter=1516)\n",
    "calc_addresses_over_threshold(pd.read_csv(FLAGGED_RESULT, chunksize=CHUNK_SIZE), 1, n_iter=1516)\n",
    "\n",
    "print('\\nTornado')\n",
    "calc_addresses_over_threshold(pd.read_csv(TORNADO_RESULT, chunksize=CHUNK_SIZE), 0.001, n_iter=984)\n",
    "calc_addresses_over_threshold(pd.read_csv(TORNADO_RESULT, chunksize=CHUNK_SIZE), 0.01, n_iter=984)\n",
    "calc_addresses_over_threshold(pd.read_csv(TORNADO_RESULT, chunksize=CHUNK_SIZE), 0.1, n_iter=984)\n",
    "calc_addresses_over_threshold(pd.read_csv(TORNADO_RESULT, chunksize=CHUNK_SIZE), 1, n_iter=984)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seniority stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "RESULT_DIR = '/media/ponbac/BigHDD/ethereum'\n",
    "SENIORITY_DIR = f'{RESULT_DIR}/blacklist/seniority'\n",
    "FLAGGED_RESULT = f'{SENIORITY_DIR}/seniority-flagged-result.csv'\n",
    "TORNADO_RESULT = f'{SENIORITY_DIR}/seniority-tornado-result.csv'\n",
    "\n",
    "CHUNK_SIZE = 100_000\n",
    "\n",
    "print('Flagged')\n",
    "calc_addresses_over_threshold(pd.read_csv(FLAGGED_RESULT, chunksize=CHUNK_SIZE), 0.001, n_iter=573, isWei=True)\n",
    "calc_addresses_over_threshold(pd.read_csv(FLAGGED_RESULT, chunksize=CHUNK_SIZE), 0.01, n_iter=573, isWei=True)\n",
    "calc_addresses_over_threshold(pd.read_csv(FLAGGED_RESULT, chunksize=CHUNK_SIZE), 0.1, n_iter=573, isWei=True)\n",
    "calc_addresses_over_threshold(pd.read_csv(FLAGGED_RESULT, chunksize=CHUNK_SIZE), 1, n_iter=573, isWei=True)\n",
    "\n",
    "print('\\nTornado')\n",
    "calc_addresses_over_threshold(pd.read_csv(TORNADO_RESULT, chunksize=CHUNK_SIZE), 0.001, n_iter=362, isWei=True)\n",
    "calc_addresses_over_threshold(pd.read_csv(TORNADO_RESULT, chunksize=CHUNK_SIZE), 0.01, n_iter=362, isWei=True)\n",
    "calc_addresses_over_threshold(pd.read_csv(TORNADO_RESULT, chunksize=CHUNK_SIZE), 0.1, n_iter=362, isWei=True)\n",
    "calc_addresses_over_threshold(pd.read_csv(TORNADO_RESULT, chunksize=CHUNK_SIZE), 1, n_iter=362, isWei=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
