{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "curr_dir = %pwd\n",
    "\n",
    "root_path = os.path.dirname(curr_dir)\n",
    "if root_path not in sys.path:\n",
    "    print(f\"Adding {root_path} to PYTHONPATH\")\n",
    "    sys.path.append(root_path)\n",
    "\n",
    "assert len(os.environ['PYTHONPATH']) > 0, \\\n",
    "            \"Set PYTHONPATH to include this repository prior to use, see README.md\"\n",
    "# assert len(os.environ['GOOGLE_APPLICATION_CREDENTIALS']) > 0, \\\n",
    "#             \"Set GOOGLE_APPLICATION_CREDENTIALS prior to use, see README.md\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Data Proccessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "\n",
    "BQ_TABLE_NAME: str = 'traces'\n",
    "BUCKET_NAME: str = f'indago'\n",
    "DOWNLOAD_DIR: str = f'/home/ponbac/dev/indago/data/raw/{BQ_TABLE_NAME}'\n",
    "# COLUMNS_TO_SAVE: Optional[List[str]] = None \n",
    "COLUMNS_TO_SAVE: Optional[List[str]] = ['block_number', 'transaction_index', 'trace_address', 'from_address', 'to_address', 'value', 'gas_used', 'status']\n",
    "MAX_BLOBS: Optional[int] = 25 # 'None' = Download all blobs to local storage.\n",
    "# MAX_BLOBS: Optional[int] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiqQuery Ethereum Table &rarr; Google Cloud Storage Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bigquery-public-data.crypto_ethereum.amended_tokens',\n",
      " 'bigquery-public-data.crypto_ethereum.balances',\n",
      " 'bigquery-public-data.crypto_ethereum.blocks',\n",
      " 'bigquery-public-data.crypto_ethereum.contracts',\n",
      " 'bigquery-public-data.crypto_ethereum.load_metadata',\n",
      " 'bigquery-public-data.crypto_ethereum.logs',\n",
      " 'bigquery-public-data.crypto_ethereum.sessions',\n",
      " 'bigquery-public-data.crypto_ethereum.token_transfers',\n",
      " 'bigquery-public-data.crypto_ethereum.tokens',\n",
      " 'bigquery-public-data.crypto_ethereum.traces',\n",
      " 'bigquery-public-data.crypto_ethereum.transactions']\n"
     ]
    }
   ],
   "source": [
    "from utils.bigquery import EthereumBigQuery\n",
    "from pprint import pprint\n",
    "\n",
    "query: EthereumBigQuery = EthereumBigQuery()\n",
    "\n",
    "# Tables available for download:\n",
    "pprint(query.get_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequest",
     "evalue": "400 Operation cannot be performed on a nested schema. Field: withdrawals; reason: invalid, message: Operation cannot be performed on a nested schema. Field: withdrawals",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Possible to export to json (as_json=True) or parquet (as_parquet=True), csv by default.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_to_bucket\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBQ_TABLE_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mBUCKET_NAME\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mBQ_TABLE_NAME\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/indago/utils/bigquery.py:95\u001b[0m, in \u001b[0;36mEthereumBigQuery.export_to_bucket\u001b[0;34m(self, table, bucket, as_json, as_parquet)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     extract_job: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mextract_table(\n\u001b[1;32m     90\u001b[0m         table_ref,\n\u001b[1;32m     91\u001b[0m         destination_uri,\n\u001b[1;32m     92\u001b[0m         location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUS\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m \u001b[43mextract_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/indago/.venv/lib/python3.10/site-packages/google/cloud/bigquery/job/base.py:971\u001b[0m, in \u001b[0;36mresult\u001b[0;34m(self, retry, timeout)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mend_column\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 971\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"int: One-based end column.\"\"\"\u001b[39;00m\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _helpers\u001b[38;5;241m.\u001b[39m_int_or_none(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_properties\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mendColumn\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/dev/indago/.venv/lib/python3.10/site-packages/google/api_core/future/polling.py:261\u001b[0m, in \u001b[0;36mresult\u001b[0;34m(self, timeout, retry, polling)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mBadRequest\u001b[0m: 400 Operation cannot be performed on a nested schema. Field: withdrawals; reason: invalid, message: Operation cannot be performed on a nested schema. Field: withdrawals"
     ]
    }
   ],
   "source": [
    "# Possible to export to json (as_json=True) or parquet (as_parquet=True), csv by default.\n",
    "query.export_to_bucket(BQ_TABLE_NAME, f'{BUCKET_NAME}/{BQ_TABLE_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported blocks to gs://indago/blocks\n"
     ]
    }
   ],
   "source": [
    "from google.cloud.bigquery import Client, DatasetReference, DestinationFormat, job, QueryJobConfig, ExtractJobConfig\n",
    "from google.api_core.page_iterator import HTTPIterator\n",
    "\n",
    "client: Client = Client(\n",
    "    location=\"US\",\n",
    ")\n",
    "dataset_id = \"bigquery-public-data.crypto_ethereum\"\n",
    "\n",
    "# Download the \"blocks\" table\n",
    "table_id = \"blocks\"\n",
    "# bucket: gs://indago/blocks\n",
    "destination_uri = f\"gs://{BUCKET_NAME}/{table_id}\"\n",
    "\n",
    "query_string = f\"\"\"SELECT\n",
    "    timestamp,\n",
    "    number,\n",
    "    `hash`,\n",
    "    parent_hash,\n",
    "    nonce,\n",
    "    sha3_uncles,\n",
    "    logs_bloom,\n",
    "    transactions_root,\n",
    "    state_root,\n",
    "    receipts_root,\n",
    "    miner,\n",
    "    difficulty,\n",
    "    total_difficulty,\n",
    "    size,\n",
    "    extra_data,\n",
    "    gas_limit,\n",
    "    gas_used,\n",
    "    transaction_count,\n",
    "    base_fee_per_gas,\n",
    "    withdrawals_root\n",
    "FROM {dataset_id}.{table_id}\"\"\"\n",
    "\n",
    "job_config = QueryJobConfig(\n",
    "    destination=\"cryptic-lattice-239701.indago.blocks\",\n",
    "    write_disposition=job.WriteDisposition.WRITE_TRUNCATE,\n",
    "    # destination_format=DestinationFormat.CSV,\n",
    ")\n",
    "\n",
    "query_job = client.query(query_string, job_config=job_config)\n",
    "query_job.result()\n",
    "\n",
    "print(f\"Exported {table_id} to {destination_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported cryptic-lattice-239701.indago.blocks to gs://indago/blocks/blocks-*.csv\n"
     ]
    }
   ],
   "source": [
    "from google.cloud.bigquery import Client, DatasetReference, DestinationFormat, job, QueryJobConfig, ExtractJobConfig\n",
    "\n",
    "table_id = \"cryptic-lattice-239701.indago.blocks\"\n",
    "\n",
    "# Extract the table to GCS\n",
    "destination_uri = f\"gs://{BUCKET_NAME}/blocks/blocks-*.csv\"\n",
    "job_config = ExtractJobConfig()\n",
    "job_config.destination_format = DestinationFormat.CSV\n",
    "extract_job = client.extract_table(\n",
    "    table_id,\n",
    "    destination_uri,\n",
    "    job_config=job_config,\n",
    ")  # Make an API request.\n",
    "extract_job.result()  # Wait for the job to complete.\n",
    "\n",
    "print(f\"Exported {table_id} to {destination_uri}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Cloud Storage Bucket &rarr; Local Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.storage.base import EthereumStorage\n",
    "from utils.storage.google_cloud_storage import GoogleCloudStorage\n",
    "\n",
    "storage: EthereumStorage = GoogleCloudStorage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [00:05<00:06,  2.37it/s]/home/ponbac/dev/indago/utils/storage/google_cloud_storage.py:51: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(os.path.join(out_dir, blob.name.split('/')[-1]), usecols=use_cols, dtype=dtypes)[use_cols].to_csv(os.path.join(out_dir, blob.name.split('/')[-1]), index=False)\n",
      " 44%|████▍     | 11/25 [00:13<00:42,  3.02s/it]/home/ponbac/dev/indago/utils/storage/google_cloud_storage.py:51: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(os.path.join(out_dir, blob.name.split('/')[-1]), usecols=use_cols, dtype=dtypes)[use_cols].to_csv(os.path.join(out_dir, blob.name.split('/')[-1]), index=False)\n",
      " 48%|████▊     | 12/25 [00:24<01:07,  5.21s/it]/home/ponbac/dev/indago/utils/storage/google_cloud_storage.py:51: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(os.path.join(out_dir, blob.name.split('/')[-1]), usecols=use_cols, dtype=dtypes)[use_cols].to_csv(os.path.join(out_dir, blob.name.split('/')[-1]), index=False)\n",
      " 52%|█████▏    | 13/25 [00:35<01:22,  6.91s/it]/home/ponbac/dev/indago/utils/storage/google_cloud_storage.py:51: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(os.path.join(out_dir, blob.name.split('/')[-1]), usecols=use_cols, dtype=dtypes)[use_cols].to_csv(os.path.join(out_dir, blob.name.split('/')[-1]), index=False)\n",
      " 56%|█████▌    | 14/25 [00:45<01:27,  7.96s/it]/home/ponbac/dev/indago/utils/storage/google_cloud_storage.py:51: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(os.path.join(out_dir, blob.name.split('/')[-1]), usecols=use_cols, dtype=dtypes)[use_cols].to_csv(os.path.join(out_dir, blob.name.split('/')[-1]), index=False)\n",
      " 60%|██████    | 15/25 [00:54<01:23,  8.38s/it]/home/ponbac/dev/indago/utils/storage/google_cloud_storage.py:51: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(os.path.join(out_dir, blob.name.split('/')[-1]), usecols=use_cols, dtype=dtypes)[use_cols].to_csv(os.path.join(out_dir, blob.name.split('/')[-1]), index=False)\n",
      " 64%|██████▍   | 16/25 [01:04<01:19,  8.82s/it]/home/ponbac/dev/indago/utils/storage/google_cloud_storage.py:51: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(os.path.join(out_dir, blob.name.split('/')[-1]), usecols=use_cols, dtype=dtypes)[use_cols].to_csv(os.path.join(out_dir, blob.name.split('/')[-1]), index=False)\n",
      " 68%|██████▊   | 17/25 [01:16<01:16,  9.61s/it]/home/ponbac/dev/indago/utils/storage/google_cloud_storage.py:51: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(os.path.join(out_dir, blob.name.split('/')[-1]), usecols=use_cols, dtype=dtypes)[use_cols].to_csv(os.path.join(out_dir, blob.name.split('/')[-1]), index=False)\n",
      " 72%|███████▏  | 18/25 [01:27<01:11, 10.15s/it]/home/ponbac/dev/indago/utils/storage/google_cloud_storage.py:51: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(os.path.join(out_dir, blob.name.split('/')[-1]), usecols=use_cols, dtype=dtypes)[use_cols].to_csv(os.path.join(out_dir, blob.name.split('/')[-1]), index=False)\n",
      " 76%|███████▌  | 19/25 [01:38<01:03, 10.51s/it]/home/ponbac/dev/indago/utils/storage/google_cloud_storage.py:51: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(os.path.join(out_dir, blob.name.split('/')[-1]), usecols=use_cols, dtype=dtypes)[use_cols].to_csv(os.path.join(out_dir, blob.name.split('/')[-1]), index=False)\n",
      " 80%|████████  | 20/25 [01:50<00:54, 10.97s/it]/home/ponbac/dev/indago/utils/storage/google_cloud_storage.py:51: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(os.path.join(out_dir, blob.name.split('/')[-1]), usecols=use_cols, dtype=dtypes)[use_cols].to_csv(os.path.join(out_dir, blob.name.split('/')[-1]), index=False)\n",
      " 84%|████████▍ | 21/25 [01:59<00:41, 10.28s/it]/home/ponbac/dev/indago/utils/storage/google_cloud_storage.py:51: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(os.path.join(out_dir, blob.name.split('/')[-1]), usecols=use_cols, dtype=dtypes)[use_cols].to_csv(os.path.join(out_dir, blob.name.split('/')[-1]), index=False)\n",
      " 88%|████████▊ | 22/25 [02:08<00:29,  9.99s/it]/home/ponbac/dev/indago/utils/storage/google_cloud_storage.py:51: DtypeWarning: Columns (4,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(os.path.join(out_dir, blob.name.split('/')[-1]), usecols=use_cols, dtype=dtypes)[use_cols].to_csv(os.path.join(out_dir, blob.name.split('/')[-1]), index=False)\n",
      " 92%|█████████▏| 23/25 [02:17<00:19,  9.74s/it]/home/ponbac/dev/indago/utils/storage/google_cloud_storage.py:51: DtypeWarning: Columns (4,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(os.path.join(out_dir, blob.name.split('/')[-1]), usecols=use_cols, dtype=dtypes)[use_cols].to_csv(os.path.join(out_dir, blob.name.split('/')[-1]), index=False)\n",
      " 96%|█████████▌| 24/25 [02:30<00:10, 10.45s/it]/home/ponbac/dev/indago/utils/storage/google_cloud_storage.py:51: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(os.path.join(out_dir, blob.name.split('/')[-1]), usecols=use_cols, dtype=dtypes)[use_cols].to_csv(os.path.join(out_dir, blob.name.split('/')[-1]), index=False)\n",
      "100%|██████████| 25/25 [02:39<00:00,  6.37s/it]\n"
     ]
    }
   ],
   "source": [
    "storage.download(BUCKET_NAME, f'{BQ_TABLE_NAME}/', DOWNLOAD_DIR, MAX_BLOBS, use_cols=COLUMNS_TO_SAVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort & Merge Downloaded Files\n",
    "Sorted and merged csv will be inside ```DOWNLOAD_DIR/processed/```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scripts.sort_big_csv as sort_big_csv\n",
    "import argparse\n",
    "\n",
    "#args = argparse.Namespace(csv_dir=DOWNLOAD_DIR, merge_only=False, sort_only=False, sort_column='block_number', out_filename=f'{BQ_TABLE_NAME}-sorted.csv')\n",
    "args = argparse.Namespace(csv_dir=DOWNLOAD_DIR,\n",
    "    merge_only=False,\n",
    "    sort_only=False,\n",
    "    sort_columns=['block_number','transaction_index'],\n",
    "    out_filename=f'{BQ_TABLE_NAME}-sorted.csv')\n",
    "#,'trace_address'\n",
    "sort_big_csv.main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
